{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default settings in Bilbac ccincide with the 'aflow' settings, except for Bilbao = hex, aflow = rhomb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fractions import Fraction\n",
    "import json\n",
    "from sympy import parse_expr,symbols\n",
    "from kim_tools import get_formal_bravais_lattice_from_space_group, get_change_of_basis_matrix_to_conventional_cell_from_formal_bravais_lattice\n",
    "import os\n",
    "\n",
    "SYMMETRY_UTIL_DATA_DIR = '../kim_tools/symmetry_util/data'\n",
    "GENPOS_MATRICES_NO_CENTERING_FILENAME = 'GENPOS_matrices_no_centering.json'\n",
    "PRIMITIVE_GENPOS_OPS_FILENAME = os.path.join(SYMMETRY_UTIL_DATA_DIR,'primitive_GENPOS_ops.json')\n",
    "TRANSLATION_COSET_REPRESENTATIVES_FILENAME = 'translation_coset_representatives.json'\n",
    "PRIMITIVE_SHIFTS_FILENAME = os.path.join(SYMMETRY_UTIL_DATA_DIR,\"possible_primitive_shifts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the primitive space group operations in the conventional setting. Meaning the basis is conventional but the additional sets of operations generated by adding centering translations are not included.\n",
    "sg_ops = {}\n",
    "\n",
    "for i in range(230):\n",
    "    sgnum = i+1\n",
    "    frames = pd.read_html(f\"https://www.cryst.ehu.es/cgi-bin/cryst/programs/nph-getgen?gnum={sgnum}&what=gp\",match=\"No\",encoding='utf8')\n",
    "    assert len(frames) == 1, \"Expected only one table\"\n",
    "    df = frames[0]\n",
    "    sg_ops[sgnum] = []\n",
    "    for op_num,op_string in zip(df[0],df[2]):\n",
    "        if op_num.isnumeric():\n",
    "           op_array = np.reshape([float(Fraction(elem)) for elem in op_string.split()],(3,4))\n",
    "           sg_ops[sgnum].append(op_array.tolist())\n",
    "     \n",
    "with open(GENPOS_MATRICES_NO_CENTERING_FILENAME,'w') as f:\n",
    "    json.dump(sg_ops,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the GENPOS augmented matrices to primitive setting. See 1.5.2.3 in ITA\n",
    "with open(GENPOS_MATRICES_NO_CENTERING_FILENAME) as f:\n",
    "    sg_ops = json.load(f)\n",
    "\n",
    "sg_ops_primitive = {}\n",
    "\n",
    "for i in range(230):\n",
    "    sgnum = i+1\n",
    "    sg_ops_primitive[sgnum] = []\n",
    "    formal_bravais_lattice = get_formal_bravais_lattice_from_space_group(sgnum)        \n",
    "    for sg_op in sg_ops[str(sgnum)]:\n",
    "        # separate matrix and column into keys, useful anyway for accessing\n",
    "        # old (unprimed) basis: conventional\n",
    "        # new (primed) basis: primitive\n",
    "        # Therefore, the below function gets us Q=P^-1 for eqs 1.5.2.12-13\n",
    "        Qmat = get_change_of_basis_matrix_to_conventional_cell_from_formal_bravais_lattice(formal_bravais_lattice)\n",
    "        Pmat = np.linalg.inv(Qmat)\n",
    "        sg_op_mat = np.asarray(sg_op)\n",
    "        Wmat = sg_op_mat[:,0:3]\n",
    "        w = sg_op_mat[:,3]\n",
    "        Wmat_prime = Qmat@Wmat@Pmat\n",
    "        w_prime = Qmat@w\n",
    "        sg_ops_primitive[sgnum].append({\n",
    "            'W': Wmat_prime.tolist(),\n",
    "            'w': w_prime.tolist()\n",
    "        })\n",
    "\n",
    "with open(PRIMITIVE_GENPOS_OPS_FILENAME,'w') as f:\n",
    "    json.dump(sg_ops_primitive,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the unique translation vectors found in the coset representatives of the space group in its normalizer.\n",
    "\n",
    "x,y,z,r,s,t = symbols(\"x y z r s t\")\n",
    "\n",
    "translation_parts={}\n",
    "\n",
    "for i in range(230):\n",
    "    sgnum = i+1\n",
    "    if sgnum > 228: # high-symmetry SGs that coincide with their normalizer\n",
    "        translation_parts[sgnum] = [(0.0, 0.0, 0.0)]\n",
    "    else:    \n",
    "        unique_translations = set()\n",
    "        data = pd.read_html(f\"https://www.cryst.ehu.es/cgi-bin/cryst/programs/nph-normsets?from=wycksets&gnum={sgnum}\",match=\"Coset Representative\",encoding='utf8')\n",
    "        for frame in data:\n",
    "            for datum in frame[\"Coset Representative\"]:\n",
    "                operations = [parse_expr(coord) for coord in datum.split(',')]\n",
    "                translations = [float(op.evalf(subs={x: 0, y: 0, z: 0, r: 0, s: 0, t: 0})) for op in operations]\n",
    "                unique_translations.add(tuple(translations))\n",
    "        translation_parts[sgnum] = sorted(list(unique_translations))\n",
    "        \n",
    "# At least for SG#9 and possibly some other monoclinic SGs, need to manually add translations from the affine normalizer from the NORMALIZER program, as they are not \n",
    "# represented in the WYCKSETS program (for SG#15 they are, as a special exception)        \n",
    "translation_parts[9]+=[\n",
    "    (0.0, 0.25, 0.0),\n",
    "    (0.0, 0.5, 0.0),\n",
    "    (0.0, 0.75, 0.0)\n",
    "    ]\n",
    "\n",
    "with open(TRANSLATION_COSET_REPRESENTATIVES_FILENAME,'w') as f:\n",
    "    json.dump(translation_parts,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PRIMITIVE_GENPOS_OPS_FILENAME) as f:\n",
    "    primitive_GENPOS_ops = json.load(f)\n",
    "with open(TRANSLATION_COSET_REPRESENTATIVES_FILENAME) as f:\n",
    "    translation_coset_representatives = json.load(f)\n",
    "    \n",
    "possible_primitive_shifts = {}\n",
    "\n",
    "for i in range(230):\n",
    "    sgnum = str(i+1)\n",
    "    possible_primitive_shifts_for_this_sg = []\n",
    "    primitive_translation_parts_for_this_sg = [GENPOS_op['w'] for GENPOS_op in primitive_GENPOS_ops[sgnum]]\n",
    "    translation_coset_representatives_for_this_sg = translation_coset_representatives[sgnum]\n",
    "    formal_bravais_lattice = get_formal_bravais_lattice_from_space_group(sgnum)\n",
    "    primitivize_matrix = np.transpose(get_change_of_basis_matrix_to_conventional_cell_from_formal_bravais_lattice(formal_bravais_lattice))\n",
    "    for translation_part_prim in primitive_translation_parts_for_this_sg:\n",
    "        for coset_rep in translation_coset_representatives_for_this_sg:\n",
    "            coset_rep_prim = coset_rep@primitivize_matrix\n",
    "            primitive_shift = translation_part_prim+coset_rep_prim\n",
    "            primitive_shift = [component%1 for component in primitive_shift]\n",
    "            already_exists = False\n",
    "            for existing_prim_shift in possible_primitive_shifts_for_this_sg:\n",
    "                if np.allclose(primitive_shift,existing_prim_shift):\n",
    "                    already_exists = True\n",
    "                    break\n",
    "            if already_exists:\n",
    "                continue\n",
    "            else:\n",
    "                possible_primitive_shifts_for_this_sg.append(primitive_shift)\n",
    "    possible_primitive_shifts[sgnum] = possible_primitive_shifts_for_this_sg\n",
    "\n",
    "with open(PRIMITIVE_SHIFTS_FILENAME,\"w\") as f:\n",
    "    json.dump(possible_primitive_shifts,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
